{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 命名实体识别"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、演练介绍\n",
    "### 1. 演练内容\n",
    "本演练中，将演练如何从不规则的文本中提取信息，将信息规则化，从而构建可以生成知识图谱的数据。\n",
    "在羡慕，演练如何从文本中识别命名实体。\n",
    "\n",
    "### 2. 演练技能点\n",
    "在本演练中，将涉及\n",
    "- 命名实体识别任务的定义与理论解决方法\n",
    "- 命名实体识别任务中的数据集处理方法\n",
    "- 命名实体识别模型——BiLstm-CRF 的理论知识\n",
    "- 用 Keras 构建 BiLstm-CRF 模型\n",
    "- BiLstm-CRF 的训练与预测方法\n",
    "\n",
    "### 3. 演练要求\n",
    "本演练要求具备以下基本能力：\n",
    "- Keras 的基本使用方法\n",
    "- 一定的数学基础\n",
    "\n",
    "\n",
    "## 二、演练原理\n",
    "\n",
    "### 1. 命名实体识别任务\n",
    "命名实体识别是自然语言处理中的一项基础任务，命名实体指文本中具有特定意义的实体，通常包括人名，地名，专有名词等。\n",
    "\n",
    "如在文本“张无忌，金庸武侠小说《倚天屠龙记》人物角色，中土明教第三十四代教主。武当七侠之一张翠山与天鹰教紫微堂主殷素素之子，明教四大护教法王之一金毛狮王谢逊义子。” 中，\n",
    "- 人名实体有：张无忌，张翠山，殷素素，谢逊\n",
    "- 书名实体有：倚天屠龙记\n",
    "- 门派实体有：明教，武当，天鹰教\n",
    "\n",
    "因此，命名实体识别任务通常包括两部分\n",
    "- 实体的边界识别：如正确识别“张翠山”，而不是“张翠”或“张翠山与”等\n",
    "- 确定实体的类型：如张无忌为人名实体，而不是门派实体或者书名实体\n",
    "\n",
    "命名实体的标注方法有多种，在本演练中使用 BMEO 标注方法\n",
    "- B 实体词首\n",
    "- M 实体词中\n",
    "- E 实体词尾\n",
    "- O 非实体\n",
    "\n",
    "结合实体类型，“武当七侠之一张翠山与天鹰教紫微堂主殷素素之子” 这份文本就会被标注为“武/门派_B 当/门派_E 七/O 侠/O 之/O 一/O 张/人名_B 翠/人名_M 山/人名_E 与/O 天/门派_B 鹰/门派_M 教/门派_E 紫/O 微/O 堂/O 主/O 殷/人名_B 素/人名_M 素/人名_E 之/O 子/O”\n",
    "\n",
    "\n",
    "\n",
    "### <a id=\"序列标注\">2. 序列标注</a>\n",
    "命名实体识别任务本质上是一个序列标注问题，即给序列中的每一帧进行分类，在这里每一帧代表一个字。如”武当七侠之一张翠山“，不考虑实体类型，则共有四个标签 BMEO。既然是分类问题，就很自然地想到逐帧分类：即训练一个判别器，输入一个字，输出该字的类别，如下图所示\n",
    "\n",
    "![softmax.png](01.png)\n",
    "\n",
    "但是实际上，并不是说“张”这个字一定代表实体词首，有可能是“张开”这个词的起始，但“张开”并非实体。因此，每一帧都是上下文关联的，如“张”后面跟着“翠山”，那么“张”就是实体词首，反之则不一定，如下图所示\n",
    "\n",
    "![crf.png](02.png)\n",
    "\n",
    "\n",
    "同时目标输出序列本身会带有一些上下文的关联，比如实体词尾前一帧不可能是非实体，实体词中后一帧要么是实体词中要么是实体词尾。这与普通的分类任务不同。如果一个输入有 $n$ 帧，每一帧的标签有 $k$ 种可能性，那么理论上就有 $k^n$ 种不同的输出。如下图所示，每一个点代表一个标签的可能性，点之间的连线表示标签之间的关联，而每一条完整的路径，表示一种输出。\n",
    "\n",
    "![graph.png](3.png)\n",
    "\n",
    "综上所述，逐帧分类是将序列标注看成 $n$ 个 $k$ 分类问题，而真正的序列标注是 1 个 $k^n$ 分类问题。\n",
    "\n",
    "### 3. 条件随机场\n",
    "条件随机场（conditional random field，简称 CRF），是是一种鉴别式机率模型。在序列标注问题中，我们要计算的是条件概率 $P(y_1,...,y_n|x), x=(x_1,...,x_n)$ 。结合前面[序列标注](#序列标注)的内容，可以理解为给予图中的边以权重，并找到权重最高的一条路径作为输出。\n",
    "CRF 中定义了特征函数来给边赋予权重，特征函数定义为 $f(s,i,l_i,l_{i-1})$ \n",
    "- $s$ 输入的句子\n",
    "- $i$ 句子 $s$ 中第 $i$ 个词\n",
    "- $l_i$ 第 $i$ 个词的标签\n",
    "- $l_i-1$ 第 $i-1$ 个词的标签\n",
    "\n",
    "定义好特征函数后，给每一个特征函数$f_j$赋予一个权重$\\lambda_j$，从而，对于输入 $s$ 和 标注序列 $l$，$l$ 的评分为\n",
    "\n",
    "$score(l|s)=\\sum^m_{j=1}\\sum^n_{i=1}\\lambda_j f_j(s,i,l_i,l_{i-1})$\n",
    "\n",
    "对分数进行指数化和标准化，就可以得到标注序列 $l$ 的概率值 $p(l|s)$，如下所示\n",
    "\n",
    "$p(l|s)=\\frac{\\exp[score(l|s)]}{\\sum_{l'}\\exp[score(l'|s)]}$\n",
    "\n",
    "### 4. BiLSTM-CRF\n",
    "长短期记忆网络（Long Short-Term Memory，简称 LSTM），是循环神经网络（Recurrent Neural Network，简称 RNN）的一种，BiLSTM 是由前向 LSTM 与后向 LSTM 组合而成，由于其设计的特点，在自然语言处理任务中都常被用来建模上下文信息。 \n",
    "\n",
    "与 CRF 不同的是，BiLSTM 依靠神经网络超强的非线性拟合能力，在训练时将数据变换到高维度的非线性空间中去，从而学习出一个模型。虽然 BiLSTM 的精度非常的高，但是在预测时，会出现一些明显的错误，如实体词尾后一帧依然预测为实体词尾等，而在 CRF 中，因为特征函数的存在，限定了标签之间的关系。因此，将 CRF 接到 BiLSTM 上，就可以将两者的特点结合，取长补短，通过 BiLSTM 提取高效的特征，让 CRF 的学习更加有效。\n",
    "\n",
    "\n",
    "## 三、演练步骤\n",
    "先安装需要的包："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用前一个演练的 tf 和 keras 即可\n",
    "#!pip install tensorflow==1.13.1\n",
    "#!pip install keras==2.2.4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 数据处理\n",
    "\n",
    "原始文本和标签分别定义为"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('张无忌，金庸武侠小说《倚天屠龙记》人物角色，中土明教第三十四代教主。武当七侠之一张翠山与天鹰教紫微堂主殷素素之子，明教四大护教法王之一金毛狮王谢逊义子。\\n              张翠山，《倚天屠龙记》第一卷的男主角，在武当七侠之中排行第五，人称张五侠。与天鹰教殷素素结为夫妇，生下张无忌，后流落到北极冰海上的冰火岛，与谢逊相识并结为兄弟。\\n              殷素素，金庸武侠小说《倚天屠龙记》第一卷的女主人公。天鹰教紫薇堂堂主，容貌娇艳无伦，智计百出，亦正亦邪。与武当五侠张翠山同赴王盘山，结果被金毛狮王谢逊强行带走，三人辗转抵达冰火岛。殷素素与张翠山在岛上结为夫妇，并诞下一子张无忌。\\n              谢逊，是金庸武侠小说《倚天屠龙记》中的人物，字退思，在明教四大护教法王中排行第三，因其满头金发，故绰号“金毛狮王”。\\n           ',\n",
       " {'name': ['张无忌', '张翠山', '殷素素', '谢逊'],\n",
       "  'book': ['倚天屠龙记'],\n",
       "  'org': ['明教', '武当', '天鹰教']})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_text = '''张无忌，金庸武侠小说《倚天屠龙记》人物角色，中土明教第三十四代教主。武当七侠之一张翠山与天鹰教紫微堂主殷素素之子，明教四大护教法王之一金毛狮王谢逊义子。\n",
    "              张翠山，《倚天屠龙记》第一卷的男主角，在武当七侠之中排行第五，人称张五侠。与天鹰教殷素素结为夫妇，生下张无忌，后流落到北极冰海上的冰火岛，与谢逊相识并结为兄弟。\n",
    "              殷素素，金庸武侠小说《倚天屠龙记》第一卷的女主人公。天鹰教紫薇堂堂主，容貌娇艳无伦，智计百出，亦正亦邪。与武当五侠张翠山同赴王盘山，结果被金毛狮王谢逊强行带走，三人辗转抵达冰火岛。殷素素与张翠山在岛上结为夫妇，并诞下一子张无忌。\n",
    "              谢逊，是金庸武侠小说《倚天屠龙记》中的人物，字退思，在明教四大护教法王中排行第三，因其满头金发，故绰号“金毛狮王”。\n",
    "           '''\n",
    "annotations = {'name':['张无忌','张翠山','殷素素','谢逊'], 'book':['倚天屠龙记'],'org':['明教','武当','天鹰教']}\n",
    "raw_text, annotations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1将标注转换为 BMEO 格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "张 name_B\n",
      "无 name_M\n",
      "忌 name_E\n",
      "， O\n",
      "金 O\n",
      "庸 O\n",
      "武 O\n",
      "侠 O\n",
      "小 O\n",
      "说 O\n",
      "《 O\n",
      "倚 book_B\n",
      "天 book_M\n",
      "屠 book_M\n",
      "龙 book_M\n",
      "记 book_E\n",
      "》 O\n",
      "人 O\n",
      "物 O\n",
      "角 O\n",
      "色 O\n",
      "， O\n",
      "中 O\n",
      "土 O\n",
      "明 org_B\n",
      "教 org_E\n",
      "第 O\n",
      "三 O\n",
      "十 O\n",
      "四 O\n",
      "代 O\n",
      "教 O\n",
      "主 O\n",
      "。 O\n",
      "武 org_B\n",
      "当 org_E\n",
      "七 O\n",
      "侠 O\n",
      "之 O\n",
      "一 O\n",
      "张 name_B\n",
      "翠 name_M\n",
      "山 name_E\n",
      "与 O\n",
      "天 org_B\n",
      "鹰 org_M\n",
      "教 org_E\n",
      "紫 O\n",
      "微 O\n",
      "堂 O\n",
      "主 O\n",
      "殷 name_B\n",
      "素 name_M\n",
      "素 name_E\n",
      "之 O\n",
      "子 O\n",
      "， O\n",
      "明 org_B\n",
      "教 org_E\n",
      "四 O\n",
      "大 O\n",
      "护 O\n",
      "教 O\n",
      "法 O\n",
      "王 O\n",
      "之 O\n",
      "一 O\n",
      "金 O\n",
      "毛 O\n",
      "狮 O\n",
      "王 O\n",
      "谢 name_B\n",
      "逊 name_E\n",
      "义 O\n",
      "子 O\n",
      "。 O\n",
      "张 name_B\n",
      "翠 name_M\n",
      "山 name_E\n",
      "， O\n",
      "《 O\n",
      "倚 book_B\n",
      "天 book_M\n",
      "屠 book_M\n",
      "龙 book_M\n",
      "记 book_E\n",
      "》 O\n",
      "第 O\n",
      "一 O\n",
      "卷 O\n",
      "的 O\n",
      "男 O\n",
      "主 O\n",
      "角 O\n",
      "， O\n",
      "在 O\n",
      "武 org_B\n",
      "当 org_E\n",
      "七 O\n",
      "侠 O\n",
      "之 O\n",
      "中 O\n",
      "排 O\n",
      "行 O\n",
      "第 O\n",
      "五 O\n",
      "， O\n",
      "人 O\n",
      "称 O\n",
      "张 O\n",
      "五 O\n",
      "侠 O\n",
      "。 O\n",
      "与 O\n",
      "天 org_B\n",
      "鹰 org_M\n",
      "教 org_E\n",
      "殷 name_B\n",
      "素 name_M\n",
      "素 name_E\n",
      "结 O\n",
      "为 O\n",
      "夫 O\n",
      "妇 O\n",
      "， O\n",
      "生 O\n",
      "下 O\n",
      "张 name_B\n",
      "无 name_M\n",
      "忌 name_E\n",
      "， O\n",
      "后 O\n",
      "流 O\n",
      "落 O\n",
      "到 O\n",
      "北 O\n",
      "极 O\n",
      "冰 O\n",
      "海 O\n",
      "上 O\n",
      "的 O\n",
      "冰 O\n",
      "火 O\n",
      "岛 O\n",
      "， O\n",
      "与 O\n",
      "谢 name_B\n",
      "逊 name_E\n",
      "相 O\n",
      "识 O\n",
      "并 O\n",
      "结 O\n",
      "为 O\n",
      "兄 O\n",
      "弟 O\n",
      "。 O\n",
      "殷 name_B\n",
      "素 name_M\n",
      "素 name_E\n",
      "， O\n",
      "金 O\n",
      "庸 O\n",
      "武 O\n",
      "侠 O\n",
      "小 O\n",
      "说 O\n",
      "《 O\n",
      "倚 book_B\n",
      "天 book_M\n",
      "屠 book_M\n",
      "龙 book_M\n",
      "记 book_E\n",
      "》 O\n",
      "第 O\n",
      "一 O\n",
      "卷 O\n",
      "的 O\n",
      "女 O\n",
      "主 O\n",
      "人 O\n",
      "公 O\n",
      "。 O\n",
      "天 org_B\n",
      "鹰 org_M\n",
      "教 org_E\n",
      "紫 O\n",
      "薇 O\n",
      "堂 O\n",
      "堂 O\n",
      "主 O\n",
      "， O\n",
      "容 O\n",
      "貌 O\n",
      "娇 O\n",
      "艳 O\n",
      "无 O\n",
      "伦 O\n",
      "， O\n",
      "智 O\n",
      "计 O\n",
      "百 O\n",
      "出 O\n",
      "， O\n",
      "亦 O\n",
      "正 O\n",
      "亦 O\n",
      "邪 O\n",
      "。 O\n",
      "与 O\n",
      "武 org_B\n",
      "当 org_E\n",
      "五 O\n",
      "侠 O\n",
      "张 name_B\n",
      "翠 name_M\n",
      "山 name_E\n",
      "同 O\n",
      "赴 O\n",
      "王 O\n",
      "盘 O\n",
      "山 O\n",
      "， O\n",
      "结 O\n",
      "果 O\n",
      "被 O\n",
      "金 O\n",
      "毛 O\n",
      "狮 O\n",
      "王 O\n",
      "谢 name_B\n",
      "逊 name_E\n",
      "强 O\n",
      "行 O\n",
      "带 O\n",
      "走 O\n",
      "， O\n",
      "三 O\n",
      "人 O\n",
      "辗 O\n",
      "转 O\n",
      "抵 O\n",
      "达 O\n",
      "冰 O\n",
      "火 O\n",
      "岛 O\n",
      "。 O\n",
      "殷 name_B\n",
      "素 name_M\n",
      "素 name_E\n",
      "与 O\n",
      "张 name_B\n",
      "翠 name_M\n",
      "山 name_E\n",
      "在 O\n",
      "岛 O\n",
      "上 O\n",
      "结 O\n",
      "为 O\n",
      "夫 O\n",
      "妇 O\n",
      "， O\n",
      "并 O\n",
      "诞 O\n",
      "下 O\n",
      "一 O\n",
      "子 O\n",
      "张 name_B\n",
      "无 name_M\n",
      "忌 name_E\n",
      "。 O\n",
      "谢 name_B\n",
      "逊 name_E\n",
      "， O\n",
      "是 O\n",
      "金 O\n",
      "庸 O\n",
      "武 O\n",
      "侠 O\n",
      "小 O\n",
      "说 O\n",
      "《 O\n",
      "倚 book_B\n",
      "天 book_M\n",
      "屠 book_M\n",
      "龙 book_M\n",
      "记 book_E\n",
      "》 O\n",
      "中 O\n",
      "的 O\n",
      "人 O\n",
      "物 O\n",
      "， O\n",
      "字 O\n",
      "退 O\n",
      "思 O\n",
      "， O\n",
      "在 O\n",
      "明 org_B\n",
      "教 org_E\n",
      "四 O\n",
      "大 O\n",
      "护 O\n",
      "教 O\n",
      "法 O\n",
      "王 O\n",
      "中 O\n",
      "排 O\n",
      "行 O\n",
      "第 O\n",
      "三 O\n",
      "， O\n",
      "因 O\n",
      "其 O\n",
      "满 O\n",
      "头 O\n",
      "金 O\n",
      "发 O\n",
      "， O\n",
      "故 O\n",
      "绰 O\n",
      "号 O\n",
      "“ O\n",
      "金 O\n",
      "毛 O\n",
      "狮 O\n",
      "王 O\n",
      "” O\n",
      "。 O\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# 先去掉原始文本中的换行和空格符\n",
    "raw_text = raw_text.replace('\\n', '').replace(' ', '')\n",
    "# 初始化 label：将其全部初始化为 O\n",
    "labels = len(raw_text)*['O']\n",
    "\n",
    "# 通过 key-value 的方式遍历 annotations 字典，进行转换\n",
    "for ann, entities in annotations.items():\n",
    "    for entity in entities:\n",
    "        # 先生成实体对应的 BME 标注类型\n",
    "        B, M, E = [['{}_{}'.format(ann,i)] for i in ['B','M','E']]\n",
    "        # 计算实体词中的数量\n",
    "        M_len = len(entity) - 2\n",
    "        # 生成 label，如果词中数为0，则直接为 BE，不然按数量添加 M\n",
    "        label = B + M * M_len + E if M_len else B + E\n",
    "        # 从原始文本中找到实体对应出现的所有位置\n",
    "        idxs = [r.start() for r in re.finditer(entity, raw_text)]\n",
    "        \n",
    "        for idx in idxs:\n",
    "        # 替换原 label 中的 O 为实际 label\n",
    "            labels[idx:idx+len(entity)] = label\n",
    "\n",
    "\n",
    "# 打印原始文本和对应转换后的 label\n",
    "for ann,label in zip(raw_text,labels):\n",
    "    print(ann, label)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 数据集预处理\n",
    "在自然语言处理中，需要将文本数据特征提取为向量数据，才能被模型使用。在本演练中使用的是词袋模型，忽略文本的语法和语序要素，将其仅仅看做是若干个词汇的集合。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先统计训练集中每个字出现的次数，然后建立字典表，只记录出现次数不小于 2 的字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Counter({'张': 8,\n",
       "          '无': 4,\n",
       "          '忌': 3,\n",
       "          '，': 21,\n",
       "          '金': 7,\n",
       "          '庸': 3,\n",
       "          '武': 6,\n",
       "          '侠': 7,\n",
       "          '小': 3,\n",
       "          '说': 3,\n",
       "          '《': 4,\n",
       "          '倚': 4,\n",
       "          '天': 7,\n",
       "          '屠': 4,\n",
       "          '龙': 4,\n",
       "          '记': 4,\n",
       "          '》': 4,\n",
       "          '人': 5,\n",
       "          '物': 2,\n",
       "          '角': 2,\n",
       "          '色': 1,\n",
       "          '中': 4,\n",
       "          '土': 1,\n",
       "          '明': 3,\n",
       "          '教': 9,\n",
       "          '第': 5,\n",
       "          '三': 3,\n",
       "          '十': 1,\n",
       "          '四': 3,\n",
       "          '代': 1,\n",
       "          '主': 5,\n",
       "          '。': 9,\n",
       "          '当': 3,\n",
       "          '七': 2,\n",
       "          '之': 4,\n",
       "          '一': 5,\n",
       "          '翠': 4,\n",
       "          '山': 5,\n",
       "          '与': 5,\n",
       "          '鹰': 3,\n",
       "          '紫': 2,\n",
       "          '微': 1,\n",
       "          '堂': 3,\n",
       "          '殷': 4,\n",
       "          '素': 8,\n",
       "          '子': 3,\n",
       "          '大': 2,\n",
       "          '护': 2,\n",
       "          '法': 2,\n",
       "          '王': 6,\n",
       "          '毛': 3,\n",
       "          '狮': 3,\n",
       "          '谢': 4,\n",
       "          '逊': 4,\n",
       "          '义': 1,\n",
       "          '卷': 2,\n",
       "          '的': 4,\n",
       "          '男': 1,\n",
       "          '在': 3,\n",
       "          '排': 2,\n",
       "          '行': 3,\n",
       "          '五': 3,\n",
       "          '称': 1,\n",
       "          '结': 4,\n",
       "          '为': 3,\n",
       "          '夫': 2,\n",
       "          '妇': 2,\n",
       "          '生': 1,\n",
       "          '下': 2,\n",
       "          '后': 1,\n",
       "          '流': 1,\n",
       "          '落': 1,\n",
       "          '到': 1,\n",
       "          '北': 1,\n",
       "          '极': 1,\n",
       "          '冰': 3,\n",
       "          '海': 1,\n",
       "          '上': 2,\n",
       "          '火': 2,\n",
       "          '岛': 3,\n",
       "          '相': 1,\n",
       "          '识': 1,\n",
       "          '并': 2,\n",
       "          '兄': 1,\n",
       "          '弟': 1,\n",
       "          '女': 1,\n",
       "          '公': 1,\n",
       "          '薇': 1,\n",
       "          '容': 1,\n",
       "          '貌': 1,\n",
       "          '娇': 1,\n",
       "          '艳': 1,\n",
       "          '伦': 1,\n",
       "          '智': 1,\n",
       "          '计': 1,\n",
       "          '百': 1,\n",
       "          '出': 1,\n",
       "          '亦': 2,\n",
       "          '正': 1,\n",
       "          '邪': 1,\n",
       "          '同': 1,\n",
       "          '赴': 1,\n",
       "          '盘': 1,\n",
       "          '果': 1,\n",
       "          '被': 1,\n",
       "          '强': 1,\n",
       "          '带': 1,\n",
       "          '走': 1,\n",
       "          '辗': 1,\n",
       "          '转': 1,\n",
       "          '抵': 1,\n",
       "          '达': 1,\n",
       "          '诞': 1,\n",
       "          '是': 1,\n",
       "          '字': 1,\n",
       "          '退': 1,\n",
       "          '思': 1,\n",
       "          '因': 1,\n",
       "          '其': 1,\n",
       "          '满': 1,\n",
       "          '头': 1,\n",
       "          '发': 1,\n",
       "          '故': 1,\n",
       "          '绰': 1,\n",
       "          '号': 1,\n",
       "          '“': 1,\n",
       "          '”': 1}),\n",
       " ['张',\n",
       "  '无',\n",
       "  '忌',\n",
       "  '，',\n",
       "  '金',\n",
       "  '庸',\n",
       "  '武',\n",
       "  '侠',\n",
       "  '小',\n",
       "  '说',\n",
       "  '《',\n",
       "  '倚',\n",
       "  '天',\n",
       "  '屠',\n",
       "  '龙',\n",
       "  '记',\n",
       "  '》',\n",
       "  '人',\n",
       "  '物',\n",
       "  '角',\n",
       "  '中',\n",
       "  '明',\n",
       "  '教',\n",
       "  '第',\n",
       "  '三',\n",
       "  '四',\n",
       "  '主',\n",
       "  '。',\n",
       "  '当',\n",
       "  '七',\n",
       "  '之',\n",
       "  '一',\n",
       "  '翠',\n",
       "  '山',\n",
       "  '与',\n",
       "  '鹰',\n",
       "  '紫',\n",
       "  '堂',\n",
       "  '殷',\n",
       "  '素',\n",
       "  '子',\n",
       "  '大',\n",
       "  '护',\n",
       "  '法',\n",
       "  '王',\n",
       "  '毛',\n",
       "  '狮',\n",
       "  '谢',\n",
       "  '逊',\n",
       "  '卷',\n",
       "  '的',\n",
       "  '在',\n",
       "  '排',\n",
       "  '行',\n",
       "  '五',\n",
       "  '结',\n",
       "  '为',\n",
       "  '夫',\n",
       "  '妇',\n",
       "  '下',\n",
       "  '冰',\n",
       "  '上',\n",
       "  '火',\n",
       "  '岛',\n",
       "  '并',\n",
       "  '亦'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 统计每个字出现的次数\n",
    "word_counts = Counter(raw_text)\n",
    "# 建立字典表，只记录出现次数不小于 2 的字\n",
    "vocab = [w for w, f in iter(word_counts.items()) if f >= 2]\n",
    "word_counts, vocab"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "原始的数据集是字符串格式的，每句话用句号隔开，在训练过程中，需要把每句话拆开作为一个样本，因为每句话的长度不同，所以要定义一个最大长度，对于小于这个最大长度的句子，在左边或者右边填充固定的数字。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array(['张', '无', '忌', '，', '金', '庸', '武', '侠', '小', '说', '《', '倚', '天',\n",
       "         '屠', '龙', '记', '》', '人', '物', '角', '色', '，', '中', '土', '明', '教',\n",
       "         '第', '三', '十', '四', '代', '教', '主', '。'], dtype='<U1'),\n",
       "  array(['武', '当', '七', '侠', '之', '一', '张', '翠', '山', '与', '天', '鹰', '教',\n",
       "         '紫', '微', '堂', '主', '殷', '素', '素', '之', '子', '，', '明', '教', '四',\n",
       "         '大', '护', '教', '法', '王', '之', '一', '金', '毛', '狮', '王', '谢', '逊',\n",
       "         '义', '子', '。'], dtype='<U1'),\n",
       "  array(['张', '翠', '山', '，', '《', '倚', '天', '屠', '龙', '记', '》', '第', '一',\n",
       "         '卷', '的', '男', '主', '角', '，', '在', '武', '当', '七', '侠', '之', '中',\n",
       "         '排', '行', '第', '五', '，', '人', '称', '张', '五', '侠', '。'], dtype='<U1'),\n",
       "  array(['与', '天', '鹰', '教', '殷', '素', '素', '结', '为', '夫', '妇', '，', '生',\n",
       "         '下', '张', '无', '忌', '，', '后', '流', '落', '到', '北', '极', '冰', '海',\n",
       "         '上', '的', '冰', '火', '岛', '，', '与', '谢', '逊', '相', '识', '并', '结',\n",
       "         '为', '兄', '弟', '。'], dtype='<U1'),\n",
       "  array(['殷', '素', '素', '，', '金', '庸', '武', '侠', '小', '说', '《', '倚', '天',\n",
       "         '屠', '龙', '记', '》', '第', '一', '卷', '的', '女', '主', '人', '公', '。'],\n",
       "        dtype='<U1'),\n",
       "  array(['天', '鹰', '教', '紫', '薇', '堂', '堂', '主', '，', '容', '貌', '娇', '艳',\n",
       "         '无', '伦', '，', '智', '计', '百', '出', '，', '亦', '正', '亦', '邪', '。'],\n",
       "        dtype='<U1'),\n",
       "  array(['与', '武', '当', '五', '侠', '张', '翠', '山', '同', '赴', '王', '盘', '山',\n",
       "         '，', '结', '果', '被', '金', '毛', '狮', '王', '谢', '逊', '强', '行', '带',\n",
       "         '走', '，', '三', '人', '辗', '转', '抵', '达', '冰', '火', '岛', '。'],\n",
       "        dtype='<U1'),\n",
       "  array(['殷', '素', '素', '与', '张', '翠', '山', '在', '岛', '上', '结', '为', '夫',\n",
       "         '妇', '，', '并', '诞', '下', '一', '子', '张', '无', '忌', '。'], dtype='<U1'),\n",
       "  array(['谢', '逊', '，', '是', '金', '庸', '武', '侠', '小', '说', '《', '倚', '天',\n",
       "         '屠', '龙', '记', '》', '中', '的', '人', '物', '，', '字', '退', '思', '，',\n",
       "         '在', '明', '教', '四', '大', '护', '教', '法', '王', '中', '排', '行', '第',\n",
       "         '三', '，', '因', '其', '满', '头', '金', '发', '，', '故', '绰', '号', '“',\n",
       "         '金', '毛', '狮', '王', '”', '。'], dtype='<U1')],\n",
       " [array(['name_B', 'name_M', 'name_E', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
       "         'O', 'book_B', 'book_M', 'book_M', 'book_M', 'book_E', 'O', 'O',\n",
       "         'O', 'O', 'O', 'O', 'O', 'O', 'org_B', 'org_E', 'O', 'O', 'O', 'O',\n",
       "         'O', 'O', 'O', 'O'], dtype='<U6'),\n",
       "  array(['org_B', 'org_E', 'O', 'O', 'O', 'O', 'name_B', 'name_M', 'name_E',\n",
       "         'O', 'org_B', 'org_M', 'org_E', 'O', 'O', 'O', 'O', 'name_B',\n",
       "         'name_M', 'name_E', 'O', 'O', 'O', 'org_B', 'org_E', 'O', 'O', 'O',\n",
       "         'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'name_B', 'name_E',\n",
       "         'O', 'O', 'O'], dtype='<U6'),\n",
       "  array(['name_B', 'name_M', 'name_E', 'O', 'O', 'book_B', 'book_M',\n",
       "         'book_M', 'book_M', 'book_E', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
       "         'O', 'O', 'O', 'org_B', 'org_E', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
       "         'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], dtype='<U6'),\n",
       "  array(['O', 'org_B', 'org_M', 'org_E', 'name_B', 'name_M', 'name_E', 'O',\n",
       "         'O', 'O', 'O', 'O', 'O', 'O', 'name_B', 'name_M', 'name_E', 'O',\n",
       "         'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
       "         'O', 'O', 'name_B', 'name_E', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
       "         'O'], dtype='<U6'),\n",
       "  array(['name_B', 'name_M', 'name_E', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
       "         'O', 'book_B', 'book_M', 'book_M', 'book_M', 'book_E', 'O', 'O',\n",
       "         'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], dtype='<U6'),\n",
       "  array(['org_B', 'org_M', 'org_E', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
       "         'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
       "         'O', 'O'], dtype='<U6'),\n",
       "  array(['O', 'org_B', 'org_E', 'O', 'O', 'name_B', 'name_M', 'name_E', 'O',\n",
       "         'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
       "         'name_B', 'name_E', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
       "         'O', 'O', 'O', 'O', 'O', 'O'], dtype='<U6'),\n",
       "  array(['name_B', 'name_M', 'name_E', 'O', 'name_B', 'name_M', 'name_E',\n",
       "         'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
       "         'name_B', 'name_M', 'name_E', 'O'], dtype='<U6'),\n",
       "  array(['name_B', 'name_E', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
       "         'book_B', 'book_M', 'book_M', 'book_M', 'book_E', 'O', 'O', 'O',\n",
       "         'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'org_B', 'org_E', 'O', 'O',\n",
       "         'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
       "         'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
       "         'O'], dtype='<U6')])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_set = list(set(labels))\n",
    "\n",
    "# 拆分训练集，每一句话作为一个样本，先找到每个句号的位置\n",
    "sentence_len = [r.start()+1 for r in re.finditer('。', raw_text)]\n",
    "\n",
    "# 进行拆分，这里要注意最后一个句号后面不需要拆分，所以最后一个位置不需要取到\n",
    "split_text = np.split(list(raw_text), sentence_len[:-1])\n",
    "split_label = np.split(labels, sentence_len[:-1])\n",
    "split_text, split_label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'张': 2,\n",
       "  '无': 3,\n",
       "  '忌': 4,\n",
       "  '，': 5,\n",
       "  '金': 6,\n",
       "  '庸': 7,\n",
       "  '武': 8,\n",
       "  '侠': 9,\n",
       "  '小': 10,\n",
       "  '说': 11,\n",
       "  '《': 12,\n",
       "  '倚': 13,\n",
       "  '天': 14,\n",
       "  '屠': 15,\n",
       "  '龙': 16,\n",
       "  '记': 17,\n",
       "  '》': 18,\n",
       "  '人': 19,\n",
       "  '物': 20,\n",
       "  '角': 21,\n",
       "  '中': 22,\n",
       "  '明': 23,\n",
       "  '教': 24,\n",
       "  '第': 25,\n",
       "  '三': 26,\n",
       "  '四': 27,\n",
       "  '主': 28,\n",
       "  '。': 29,\n",
       "  '当': 30,\n",
       "  '七': 31,\n",
       "  '之': 32,\n",
       "  '一': 33,\n",
       "  '翠': 34,\n",
       "  '山': 35,\n",
       "  '与': 36,\n",
       "  '鹰': 37,\n",
       "  '紫': 38,\n",
       "  '堂': 39,\n",
       "  '殷': 40,\n",
       "  '素': 41,\n",
       "  '子': 42,\n",
       "  '大': 43,\n",
       "  '护': 44,\n",
       "  '法': 45,\n",
       "  '王': 46,\n",
       "  '毛': 47,\n",
       "  '狮': 48,\n",
       "  '谢': 49,\n",
       "  '逊': 50,\n",
       "  '卷': 51,\n",
       "  '的': 52,\n",
       "  '在': 53,\n",
       "  '排': 54,\n",
       "  '行': 55,\n",
       "  '五': 56,\n",
       "  '结': 57,\n",
       "  '为': 58,\n",
       "  '夫': 59,\n",
       "  '妇': 60,\n",
       "  '下': 61,\n",
       "  '冰': 62,\n",
       "  '上': 63,\n",
       "  '火': 64,\n",
       "  '岛': 65,\n",
       "  '并': 66,\n",
       "  '亦': 67},\n",
       " [[8,\n",
       "   2,\n",
       "   5,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   1,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   6,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   9,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4],\n",
       "  [0,\n",
       "   9,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   8,\n",
       "   2,\n",
       "   5,\n",
       "   4,\n",
       "   0,\n",
       "   7,\n",
       "   9,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   8,\n",
       "   2,\n",
       "   5,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   9,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   8,\n",
       "   5,\n",
       "   4,\n",
       "   4,\n",
       "   4],\n",
       "  [8,\n",
       "   2,\n",
       "   5,\n",
       "   4,\n",
       "   4,\n",
       "   1,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   6,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   9,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4],\n",
       "  [4,\n",
       "   0,\n",
       "   7,\n",
       "   9,\n",
       "   8,\n",
       "   2,\n",
       "   5,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   8,\n",
       "   2,\n",
       "   5,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   8,\n",
       "   5,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4],\n",
       "  [8,\n",
       "   2,\n",
       "   5,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   1,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   6,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4],\n",
       "  [0,\n",
       "   7,\n",
       "   9,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4],\n",
       "  [4,\n",
       "   0,\n",
       "   9,\n",
       "   4,\n",
       "   4,\n",
       "   8,\n",
       "   2,\n",
       "   5,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   8,\n",
       "   5,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4],\n",
       "  [8, 2, 5, 4, 8, 2, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 8, 2, 5, 4],\n",
       "  [8,\n",
       "   5,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   1,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   6,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   0,\n",
       "   9,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 构建词袋模型，这里要将字典从 2 开始编号，把 0 和 1 空出来，0 作为填充元素，1 作为不在字典中的字的编号\n",
    "word2idx = dict((w,i+2) for i,w in enumerate(vocab))\n",
    "label2idx = [[label_set.index(w) for w in s] for s in split_label]\n",
    "word2idx, label2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9, 64), (9, 64, 1))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 构建输入，即对于样本中每一个字，从词袋模型中找到这个字对应的 idx，出现频率过低的字，并没有出现在词袋模型中，此时将这些字的 idx 取为 1\n",
    "train_x = [[word2idx.get(w, 1) for w in s] for s in split_text]\n",
    "\n",
    "max_len = 64\n",
    "\n",
    "# 在输入的左边填充 0，在输出的左端填充-1\n",
    "train_x = pad_sequences(train_x, max_len, value=0)\n",
    "train_y = pad_sequences(label2idx, max_len, value=-1)\n",
    "train_y = np.expand_dims(train_y, 2)\n",
    "train_x.shape, train_y.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 构建网络模型\n",
    "在 Keras 中，已经包含了 BiLSTM 模型中的各个组件，只需导入构建就可以了，而 CRF 层需要导入第三方库 keras-contrib 来使用。\n",
    "\n",
    "首先安装 keras-contrib\n",
    "\n",
    "方法如下：\n",
    "\n",
    "1. 下载 https://codeload.github.com/keras-team/keras-contrib/zip/refs/heads/master\n",
    "2. 解压，并执行： python setup.py install\n",
    "\n",
    "然后，修改：C:\\Dev\\Python\\venvs\\py37kg01\\Lib\\site-packages\\keras_contrib-2.0.8-py3.7.egg\\keras_contrib\\layers\\ctf.py \n",
    "\n",
    "即：keras_contrib.layers.crf.py (对  K.slice 的调用，在 Line 463)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#! pip install git+https://www.github.com/keras-team/keras-contrib.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Bidirectional, LSTM\n",
    "from keras_contrib.layers import CRF\n",
    "from keras_contrib.losses import crf_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From f:\\Venvs\\kg01\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 200)         13600     \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, None, 200)         240800    \n",
      "_________________________________________________________________\n",
      "crf_1 (CRF)                  (None, None, 9)           1908      \n",
      "=================================================================\n",
      "Total params: 256,308\n",
      "Trainable params: 256,308\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Venvs\\kg01\\lib\\site-packages\\keras_contrib\\layers\\crf.py:353: UserWarning: CRF.accuracy is deprecated and it might be removed in the future. Please use metrics.crf_accuracy\n",
      "  warnings.warn('CRF.accuracy is deprecated and it '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting git+https://www.github.com/keras-team/keras-contrib.git\n",
      "  Cloning https://www.github.com/keras-team/keras-contrib.git to c:\\users\\lxmli\\appdata\\local\\temp\\pip-req-build-zqyo32je\n",
      "  Resolved https://www.github.com/keras-team/keras-contrib.git to commit 3fc5ef709e061416f4bc8a92ca3750c824b5d2b0\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: keras in f:\\venvs\\kg01\\lib\\site-packages (from keras-contrib==2.0.8) (2.1.6)\n",
      "Requirement already satisfied: numpy>=1.9.1 in f:\\venvs\\kg01\\lib\\site-packages (from keras->keras-contrib==2.0.8) (1.21.6)\n",
      "Requirement already satisfied: scipy>=0.14 in f:\\venvs\\kg01\\lib\\site-packages (from keras->keras-contrib==2.0.8) (1.7.3)\n",
      "Requirement already satisfied: six>=1.9.0 in f:\\venvs\\kg01\\lib\\site-packages (from keras->keras-contrib==2.0.8) (1.16.0)\n",
      "Requirement already satisfied: pyyaml in f:\\venvs\\kg01\\lib\\site-packages (from keras->keras-contrib==2.0.8) (6.0)\n",
      "Requirement already satisfied: h5py in f:\\venvs\\kg01\\lib\\site-packages (from keras->keras-contrib==2.0.8) (3.8.0)\n",
      "Building wheels for collected packages: keras-contrib\n",
      "  Building wheel for keras-contrib (setup.py): started\n",
      "  Building wheel for keras-contrib (setup.py): finished with status 'done'\n",
      "  Created wheel for keras-contrib: filename=keras_contrib-2.0.8-py3-none-any.whl size=101662 sha256=647512ae8ff8dd4441e4a025ba0bbc9dd66b03de952a1c11d69b7f1486776879\n",
      "  Stored in directory: C:\\Users\\lxmli\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-3s9lm7nq\\wheels\\bb\\1f\\f2\\b57495012683b6b20bbae94a3915ec79753111452d79886abc\n",
      "Successfully built keras-contrib\n",
      "Installing collected packages: keras-contrib\n",
      "Successfully installed keras-contrib-2.0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://www.github.com/keras-team/keras-contrib.git 'C:\\Users\\lxmli\\AppData\\Local\\Temp\\pip-req-build-zqyo32je'\n",
      "  warning: redirecting to https://github.com/keras-team/keras-contrib.git/\n"
     ]
    }
   ],
   "source": [
    "# 定义模型的超参\n",
    "EMBED_DIM = 200\n",
    "BiRNN_UNITS = 200\n",
    "\n",
    "# 初始化模型\n",
    "model = Sequential()\n",
    "# 添加 Embedding 层，将输入转换成向量\n",
    "model.add(Embedding(len(vocab)+2, EMBED_DIM, mask_zero=True))\n",
    "# 添加 BiLstm 层\n",
    "model.add(Bidirectional(LSTM(BiRNN_UNITS // 2, return_sequences=True)))\n",
    "# 初始化 crf\n",
    "crf = CRF(len(train_y), sparse_target=True)\n",
    "# 将 crf 添加到模型中\n",
    "model.add(crf)\n",
    "model.summary()\n",
    "# 编译模型\n",
    "model.compile('adam', loss=crf_loss, metrics=[crf.accuracy])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 模型训练 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From f:\\Venvs\\kg01\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/120\n",
      "9/9 [==============================] - 2s 206ms/step - loss: 4.0508 - crf_viterbi_accuracy: 0.0091\n",
      "Epoch 2/120\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 4.0145 - crf_viterbi_accuracy: 0.0091\n",
      "Epoch 3/120\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 3.9767 - crf_viterbi_accuracy: 0.0091\n",
      "Epoch 4/120\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 3.9350 - crf_viterbi_accuracy: 0.0091\n",
      "Epoch 5/120\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 3.8868 - crf_viterbi_accuracy: 0.0091\n",
      "Epoch 6/120\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 3.8291 - crf_viterbi_accuracy: 0.0091\n",
      "Epoch 7/120\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 3.7580 - crf_viterbi_accuracy: 0.0091\n",
      "Epoch 8/120\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 3.6688 - crf_viterbi_accuracy: 0.2805\n",
      "Epoch 9/120\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 3.5557 - crf_viterbi_accuracy: 0.4482\n",
      "Epoch 10/120\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 3.4125 - crf_viterbi_accuracy: 0.7439\n",
      "Epoch 11/120\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 3.2383 - crf_viterbi_accuracy: 0.7500\n",
      "Epoch 12/120\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 3.0617 - crf_viterbi_accuracy: 0.7500\n",
      "Epoch 13/120\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 2.9808 - crf_viterbi_accuracy: 0.7500\n",
      "Epoch 14/120\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 2.9972 - crf_viterbi_accuracy: 0.7500\n",
      "Epoch 15/120\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 3.0260 - crf_viterbi_accuracy: 0.7500\n",
      "Epoch 16/120\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 3.0222 - crf_viterbi_accuracy: 0.7500\n",
      "Epoch 17/120\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 2.9860 - crf_viterbi_accuracy: 0.7500\n",
      "Epoch 18/120\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 2.9386 - crf_viterbi_accuracy: 0.7500\n",
      "Epoch 19/120\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 2.8960 - crf_viterbi_accuracy: 0.7500\n",
      "Epoch 20/120\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 2.8651 - crf_viterbi_accuracy: 0.7500\n",
      "Epoch 21/120\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 2.8470 - crf_viterbi_accuracy: 0.7500\n",
      "Epoch 22/120\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 2.8402 - crf_viterbi_accuracy: 0.7500\n",
      "Epoch 23/120\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 2.8409 - crf_viterbi_accuracy: 0.7500\n",
      "Epoch 24/120\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 2.8445 - crf_viterbi_accuracy: 0.7470\n",
      "Epoch 25/120\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 2.8465 - crf_viterbi_accuracy: 0.7470\n",
      "Epoch 26/120\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 2.8446 - crf_viterbi_accuracy: 0.7470\n",
      "Epoch 27/120\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 2.8381 - crf_viterbi_accuracy: 0.7470\n",
      "Epoch 28/120\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 2.8281 - crf_viterbi_accuracy: 0.7470\n",
      "Epoch 29/120\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.8165 - crf_viterbi_accuracy: 0.7470\n",
      "Epoch 30/120\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.8050 - crf_viterbi_accuracy: 0.7470\n",
      "Epoch 31/120\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.7951 - crf_viterbi_accuracy: 0.7470\n",
      "Epoch 32/120\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.7871 - crf_viterbi_accuracy: 0.7470\n",
      "Epoch 33/120\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.7810 - crf_viterbi_accuracy: 0.7470\n",
      "Epoch 34/120\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.7757 - crf_viterbi_accuracy: 0.7470\n",
      "Epoch 35/120\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.7704 - crf_viterbi_accuracy: 0.7470\n",
      "Epoch 36/120\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.7642 - crf_viterbi_accuracy: 0.7470\n",
      "Epoch 37/120\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.7568 - crf_viterbi_accuracy: 0.7470\n",
      "Epoch 38/120\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.7482 - crf_viterbi_accuracy: 0.7470\n",
      "Epoch 39/120\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.7388 - crf_viterbi_accuracy: 0.7500\n",
      "Epoch 40/120\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.7291 - crf_viterbi_accuracy: 0.7500\n",
      "Epoch 41/120\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 2.7196 - crf_viterbi_accuracy: 0.7500\n",
      "Epoch 42/120\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.7106 - crf_viterbi_accuracy: 0.7500\n",
      "Epoch 43/120\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.7021 - crf_viterbi_accuracy: 0.7500\n",
      "Epoch 44/120\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.6940 - crf_viterbi_accuracy: 0.7500\n",
      "Epoch 45/120\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.6860 - crf_viterbi_accuracy: 0.7500\n",
      "Epoch 46/120\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 2.6777 - crf_viterbi_accuracy: 0.7500\n",
      "Epoch 47/120\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.6689 - crf_viterbi_accuracy: 0.7500\n",
      "Epoch 48/120\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.6595 - crf_viterbi_accuracy: 0.7591\n",
      "Epoch 49/120\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.6496 - crf_viterbi_accuracy: 0.7591\n",
      "Epoch 50/120\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.6393 - crf_viterbi_accuracy: 0.7591\n",
      "Epoch 51/120\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 2.6287 - crf_viterbi_accuracy: 0.7591\n",
      "Epoch 52/120\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.6180 - crf_viterbi_accuracy: 0.7591\n",
      "Epoch 53/120\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.6073 - crf_viterbi_accuracy: 0.7622\n",
      "Epoch 54/120\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.5964 - crf_viterbi_accuracy: 0.7622\n",
      "Epoch 55/120\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.5855 - crf_viterbi_accuracy: 0.7622\n",
      "Epoch 56/120\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.5743 - crf_viterbi_accuracy: 0.7652\n",
      "Epoch 57/120\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.5628 - crf_viterbi_accuracy: 0.7744\n",
      "Epoch 58/120\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.5510 - crf_viterbi_accuracy: 0.7835\n",
      "Epoch 59/120\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.5390 - crf_viterbi_accuracy: 0.7988\n",
      "Epoch 60/120\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.5267 - crf_viterbi_accuracy: 0.8110\n",
      "Epoch 61/120\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.5143 - crf_viterbi_accuracy: 0.8171\n",
      "Epoch 62/120\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.5018 - crf_viterbi_accuracy: 0.8323\n",
      "Epoch 63/120\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.4894 - crf_viterbi_accuracy: 0.8323\n",
      "Epoch 64/120\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 2.4769 - crf_viterbi_accuracy: 0.8323\n",
      "Epoch 65/120\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 2.4644 - crf_viterbi_accuracy: 0.8354\n",
      "Epoch 66/120\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.4518 - crf_viterbi_accuracy: 0.8445\n",
      "Epoch 67/120\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 2.4390 - crf_viterbi_accuracy: 0.8537\n",
      "Epoch 68/120\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 2.4259 - crf_viterbi_accuracy: 0.8598\n",
      "Epoch 69/120\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.4125 - crf_viterbi_accuracy: 0.8598\n",
      "Epoch 70/120\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 2.3991 - crf_viterbi_accuracy: 0.8598\n",
      "Epoch 71/120\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.3858 - crf_viterbi_accuracy: 0.8598\n",
      "Epoch 72/120\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 2.3727 - crf_viterbi_accuracy: 0.8689\n",
      "Epoch 73/120\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 2.3597 - crf_viterbi_accuracy: 0.8780\n",
      "Epoch 74/120\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.3470 - crf_viterbi_accuracy: 0.8780\n",
      "Epoch 75/120\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 2.3345 - crf_viterbi_accuracy: 0.8872\n",
      "Epoch 76/120\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.3221 - crf_viterbi_accuracy: 0.8872\n",
      "Epoch 77/120\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.3099 - crf_viterbi_accuracy: 0.8872\n",
      "Epoch 78/120\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.2978 - crf_viterbi_accuracy: 0.8933\n",
      "Epoch 79/120\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.2858 - crf_viterbi_accuracy: 0.8933\n",
      "Epoch 80/120\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.2740 - crf_viterbi_accuracy: 0.9024\n",
      "Epoch 81/120\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.2625 - crf_viterbi_accuracy: 0.9085\n",
      "Epoch 82/120\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 2.2510 - crf_viterbi_accuracy: 0.9207\n",
      "Epoch 83/120\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.2396 - crf_viterbi_accuracy: 0.9238\n",
      "Epoch 84/120\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.2282 - crf_viterbi_accuracy: 0.9268\n",
      "Epoch 85/120\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.2171 - crf_viterbi_accuracy: 0.9268\n",
      "Epoch 86/120\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 2.2075 - crf_viterbi_accuracy: 0.9238\n",
      "Epoch 87/120\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 2.1968 - crf_viterbi_accuracy: 0.9299\n",
      "Epoch 88/120\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 2.1873 - crf_viterbi_accuracy: 0.9329\n",
      "Epoch 89/120\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 2.1778 - crf_viterbi_accuracy: 0.9451\n",
      "Epoch 90/120\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.1685 - crf_viterbi_accuracy: 0.9451\n",
      "Epoch 91/120\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 2.1593 - crf_viterbi_accuracy: 0.9512\n",
      "Epoch 92/120\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 2.1501 - crf_viterbi_accuracy: 0.9573\n",
      "Epoch 93/120\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 2.1408 - crf_viterbi_accuracy: 0.9573\n",
      "Epoch 94/120\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 2.1322 - crf_viterbi_accuracy: 0.9573\n",
      "Epoch 95/120\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 2.1249 - crf_viterbi_accuracy: 0.9634\n",
      "Epoch 96/120\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 2.1174 - crf_viterbi_accuracy: 0.9634\n",
      "Epoch 97/120\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 2.1100 - crf_viterbi_accuracy: 0.9634\n",
      "Epoch 98/120\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 2.1028 - crf_viterbi_accuracy: 0.9695\n",
      "Epoch 99/120\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 2.0960 - crf_viterbi_accuracy: 0.9695\n",
      "Epoch 100/120\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0904 - crf_viterbi_accuracy: 0.9695\n",
      "Epoch 101/120\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0840 - crf_viterbi_accuracy: 0.9665\n",
      "Epoch 102/120\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0779 - crf_viterbi_accuracy: 0.9695\n",
      "Epoch 103/120\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0710 - crf_viterbi_accuracy: 0.9695\n",
      "Epoch 104/120\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0661 - crf_viterbi_accuracy: 0.9695\n",
      "Epoch 105/120\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0595 - crf_viterbi_accuracy: 0.9695\n",
      "Epoch 106/120\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0546 - crf_viterbi_accuracy: 0.9695\n",
      "Epoch 107/120\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0484 - crf_viterbi_accuracy: 0.9695\n",
      "Epoch 108/120\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0436 - crf_viterbi_accuracy: 0.9695\n",
      "Epoch 109/120\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0381 - crf_viterbi_accuracy: 0.9695\n",
      "Epoch 110/120\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0330 - crf_viterbi_accuracy: 0.9695\n",
      "Epoch 111/120\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0282 - crf_viterbi_accuracy: 0.9695\n",
      "Epoch 112/120\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0228 - crf_viterbi_accuracy: 0.9695\n",
      "Epoch 113/120\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0182 - crf_viterbi_accuracy: 0.9695\n",
      "Epoch 114/120\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0133 - crf_viterbi_accuracy: 0.9695\n",
      "Epoch 115/120\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 2.0084 - crf_viterbi_accuracy: 0.9695\n",
      "Epoch 116/120\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 2.0039 - crf_viterbi_accuracy: 0.9695\n",
      "Epoch 117/120\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 1.9990 - crf_viterbi_accuracy: 0.9695\n",
      "Epoch 118/120\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.9947 - crf_viterbi_accuracy: 0.9695\n",
      "Epoch 119/120\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.9900 - crf_viterbi_accuracy: 0.9695\n",
      "Epoch 120/120\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.9857 - crf_viterbi_accuracy: 0.9695\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_x, train_y, batch_size=9, epochs=120)\n",
    "model.save('model.h5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 模型预测 \n",
    "在这里使用训练集中出现的一句话进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'谢逊，是金庸武侠小说《倚天屠龙记》中的人物，字退思，在明教四大护教法王中排行第三，因其满头金发，故绰号“金毛狮王\"。'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = '谢逊，是金庸武侠小说《倚天屠龙记》中的人物，字退思，在明教四大护教法王中排行第三，因其满头金发，故绰号“金毛狮王\"。'\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  0,  0, 49, 50,  5,  1,  6,  7,  8,  9, 10, 11,\n",
       "        12, 13, 14, 15, 16, 17, 18, 22, 52, 19, 20,  5,  1,  1,  1,  5,\n",
       "        53, 23, 24, 27, 43, 44, 24, 45, 46, 22, 54, 55, 25, 26,  5,  1,\n",
       "         1,  1,  1,  6,  1,  5,  1,  1,  1,  1,  6, 47, 48, 46,  1, 29]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将预测数据转换为特征向量\n",
    "pred_x = [word2idx.get(w, 1) for w in text]\n",
    "pred_x = pad_sequences([pred_x], max_len)\n",
    "pred_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 64, 9)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用模型进行预测\n",
    "pred = model.predict(pred_x)\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58, 9)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 去除多余的维度\n",
    "pred = np.squeeze(pred)[-len(text):]\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 把输出向量转换为 label 对应的 idx\n",
    "result = [np.argmax(r) for r in pred]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "谢 name_B\n",
      "逊 name_E\n",
      "， O\n",
      "是 O\n",
      "金 O\n",
      "庸 O\n",
      "武 O\n",
      "侠 O\n",
      "小 O\n",
      "说 O\n",
      "《 O\n",
      "倚 book_B\n",
      "天 book_M\n",
      "屠 book_M\n",
      "龙 book_M\n",
      "记 book_E\n",
      "》 O\n",
      "中 O\n",
      "的 O\n",
      "人 O\n",
      "物 O\n",
      "， O\n",
      "字 O\n",
      "退 O\n",
      "思 O\n",
      "， O\n",
      "在 O\n",
      "明 org_B\n",
      "教 O\n",
      "四 O\n",
      "大 O\n",
      "护 O\n",
      "教 O\n",
      "法 O\n",
      "王 O\n",
      "中 O\n",
      "排 O\n",
      "行 O\n",
      "第 O\n",
      "三 O\n",
      "， O\n",
      "因 O\n",
      "其 O\n",
      "满 O\n",
      "头 O\n",
      "金 O\n",
      "发 O\n",
      "， O\n",
      "故 O\n",
      "绰 O\n",
      "号 O\n",
      "“ O\n",
      "金 O\n",
      "毛 O\n",
      "狮 O\n",
      "王 O\n",
      "\" O\n",
      "。 O\n"
     ]
    }
   ],
   "source": [
    "# 打印输出结果\n",
    "reslut_labels = [label_set[i] for i in result]\n",
    "for w, l in zip(text, reslut_labels):\n",
    "    print(w, l)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  四、总结"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在本演练中，了解了命名实体识别任务的定义，并用了 BiLstm-CRF 模型，结合简单的数据集实现了整个命名实体识别任务中的数据处理、训练与预测。\n",
    "虽然在本演练中数据集规模较小，而且并没有切分验证集与测试集，但在实际的调试中，为了先确保数据管道与网络模型是否搭建正确，应先用少量数据集训练至过拟合，然后逐渐增大数据规模，并切分验证集和测试集，在验证集上对模型进行调优。\n",
    "\n",
    "命名实体识别除了应用在构建知识图谱前期的数据结构化之外，还可以用于知识图谱构建完成后的智能问答上，如提问 “张无忌是谁？”，从中提取到人名实体“张无忌”，然后转化为 Cypher 语言 `match (n:角色) where n.name='张无忌' return n.desc` 进行查询，最后返回查询到的结果作为回答。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 五、课后习题\n",
    "1. 尝试扩充数据集，然后切分验证集与测试集进行训练。\n",
    "2. 尝试使用函数式 API 构建 Bi-LSTM 模型。\n",
    "3. 尝试将上述代码改为 tensorflow 2.x 的版本，尝试修改代码，并重新运行，实现上述功能\n",
    "4. 思考是否有更简单的实现方式？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
